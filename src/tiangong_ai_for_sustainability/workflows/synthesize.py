"""Hybrid workflow that orchestrates deterministic research steps and LLM synthesis."""

from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

from ..adapters import AdapterError
from ..core.logging import get_logger
from ..deep_research import DeepResearchClient, ResearchPrompt
from ..services import ResearchServices
from .steps import discover_papers, discover_repositories, match_sdg_goals, retrieve_carbon_intensity


@dataclass(slots=True)
class SynthesisWorkflowArtifacts:
    """Outputs generated by :func:`run_synthesis_workflow`."""

    report_path: Path
    sdg_matches: List[Dict[str, object]]
    repositories: List[Dict[str, object]]
    papers: List[Dict[str, object]]
    carbon_snapshot: Optional[Dict[str, object]]
    llm_summary: Optional[str]
    llm_response_path: Optional[Path]
    prompt_template_identifier: Optional[str]
    prompt_template_path: Optional[Path]
    prompt_language: Optional[str]
    plan: Optional[List[str]] = None


_DEFAULT_INSTRUCTIONS = (
    "Produce a concise research briefing that connects SDG alignment, open-source tooling, "
    "recent literature, and carbon intensity considerations. Highlight actionable insights "
    "and recommend next steps for sustainability practitioners."
)


def run_synthesis_workflow(
    services: ResearchServices,
    *,
    question: str,
    report_path: Path,
    topic: Optional[str] = None,
    sdg_context: Optional[str] = None,
    repository_limit: int = 5,
    paper_limit: int = 5,
    carbon_location: Optional[str] = None,
    prompt_template: Optional[str] = None,
    prompt_language: Optional[str] = None,
    instructions_override: Optional[str] = None,
    skip_llm: bool = False,
) -> SynthesisWorkflowArtifacts:
    """
    Orchestrate deterministic data collection followed by optional LLM synthesis.

    Parameters mirror the CLI surface so Codex automations can reuse the workflow
    directly.
    """

    context = getattr(services, "context", None)
    options = getattr(context, "options", None)
    is_dry_run = bool(getattr(options, "dry_run", False))

    if hasattr(services, "context") and hasattr(services.context, "get_logger"):
        workflow_logger = services.context.get_logger("workflow.synthesize")
    else:  # pragma: no cover - fallback for tests without context
        workflow_logger = get_logger("workflow.synthesize")

    analysis_topic = (topic or question).strip()
    sdg_basis = (sdg_context or question).strip()
    report_path = report_path.resolve()

    workflow_logger.info(
        "Starting synthesis workflow",
        extra={
            "question": question,
            "topic": analysis_topic,
            "report_path": report_path.as_posix(),
            "carbon_location": carbon_location,
            "dry_run": is_dry_run,
        },
    )

    plan_steps = [
        "Match SDG goals against the supplied context.",
        f"Search GitHub repositories for '{analysis_topic}'.",
        f"Query Semantic Scholar for top {paper_limit} papers.",
    ]
    if carbon_location:
        plan_steps.append(f"Retrieve grid carbon intensity snapshot for {carbon_location}.")
    else:
        plan_steps.append("Skip carbon intensity (no location provided).")
    plan_steps.append("Run Deep Research synthesis." if not skip_llm else "Skip LLM synthesis as requested.")

    if is_dry_run:
        workflow_logger.info("Dry-run plan generated", extra={"steps": plan_steps})
        return SynthesisWorkflowArtifacts(
            report_path=report_path,
            sdg_matches=[],
            repositories=[],
            papers=[],
            carbon_snapshot=None,
            llm_summary=None,
            llm_response_path=None,
            prompt_template_identifier=None,
            prompt_template_path=None,
            prompt_language=prompt_language,
            plan=plan_steps,
        )

    report_path.parent.mkdir(parents=True, exist_ok=True)

    sdg_matches = match_sdg_goals(services, sdg_basis, workflow_logger)
    repositories = discover_repositories(services, analysis_topic, repository_limit, workflow_logger)
    papers = discover_papers(services, analysis_topic, paper_limit, logger=workflow_logger)

    carbon_snapshot: Optional[Dict[str, object]]
    if carbon_location:
        carbon_snapshot = retrieve_carbon_intensity(services, carbon_location, workflow_logger)
    else:
        carbon_snapshot = {
            "note": "Carbon intensity skipped",
            "reason": "no-location",
            "location": None,
        }

    prompt_variables = dict(getattr(options, "prompt_variables", {}) if options else {})
    prompt_variables.setdefault("topic", analysis_topic)
    prompt_variables.setdefault("question", question)

    effective_instructions = instructions_override
    loaded_template = None
    llm_summary: Optional[str] = None
    llm_response_path: Optional[Path] = None

    if not skip_llm and not effective_instructions:
        try:
            loaded_template = services.load_prompt_template(prompt_template, language=prompt_language)
        except AdapterError as exc:
            workflow_logger.warning(
                "Prompt template unavailable; falling back to default instructions",
                extra={"error": str(exc)},
            )
        else:
            rendered = loaded_template.render({k: str(v) for k, v in prompt_variables.items() if v is not None})
            effective_instructions = rendered if rendered.strip() else None

    if skip_llm:
        workflow_logger.info("Synthesis requested without LLM stage")
    else:
        try:
            prompt_context = _build_prompt_context(
                question=question,
                topic=analysis_topic,
                sdg_matches=sdg_matches,
                repositories=repositories,
                papers=papers,
                carbon_snapshot=carbon_snapshot,
            )
            client = DeepResearchClient()
            result = client.run(
                ResearchPrompt(question=question, context=prompt_context),
                instructions=effective_instructions or _DEFAULT_INSTRUCTIONS,
                max_tool_calls=30,
            )
        except Exception as exc:  # pragma: no cover - depends on runtime credentials
            workflow_logger.error("Deep Research synthesis failed", extra={"error": str(exc)})
            llm_summary = f"Deep Research unavailable: {exc}"
        else:
            llm_summary = result.output_text.strip() or None
            llm_response_path = report_path.with_suffix(".llm.json")
            llm_response_path.write_text(json.dumps(result.to_dict(), ensure_ascii=False, indent=2), encoding="utf-8")
            workflow_logger.info(
                "Deep Research synthesis completed",
                extra={"response_path": llm_response_path.as_posix()},
            )

    report_content = _render_report(
        question=question,
        topic=analysis_topic,
        sdg_matches=sdg_matches,
        repositories=repositories,
        papers=papers,
        carbon_snapshot=carbon_snapshot,
        llm_summary=llm_summary,
    )
    report_path.write_text(report_content, encoding="utf-8")
    workflow_logger.info("Synthesis report generated", extra={"report_path": report_path.as_posix()})

    return SynthesisWorkflowArtifacts(
        report_path=report_path,
        sdg_matches=sdg_matches,
        repositories=repositories,
        papers=papers,
        carbon_snapshot=carbon_snapshot,
        llm_summary=llm_summary,
        llm_response_path=llm_response_path,
        prompt_template_identifier=getattr(loaded_template, "identifier", None),
        prompt_template_path=getattr(loaded_template, "path", None),
        prompt_language=getattr(loaded_template, "language", prompt_language),
        plan=None,
    )


def _build_prompt_context(
    *,
    question: str,
    topic: str,
    sdg_matches: List[Dict[str, object]],
    repositories: List[Dict[str, object]],
    papers: List[Dict[str, object]],
    carbon_snapshot: Optional[Dict[str, object]],
) -> str:
    lines: List[str] = []
    lines.append(f"Primary question: {question}")
    lines.append(f"Topic focus: {topic}")
    lines.append("")

    lines.append("SDG matches (top 5):")
    if sdg_matches:
        for match in sdg_matches[:5]:
            lines.append(f"- SDG {match.get('code', 'N/A')}: {match.get('title', 'Unknown')} (score {match.get('score', 0)})")
    else:
        lines.append("- No SDG matches identified.")
    lines.append("")

    lines.append("Notable repositories:")
    if repositories:
        for repo in repositories[:5]:
            lines.append(f"- {repo.get('full_name', 'unknown')} — ⭐ {repo.get('stargazers_count', 0)} — {repo.get('description') or 'No description'}")
    else:
        lines.append("- No repositories discovered.")
    lines.append("")

    lines.append("Representative papers:")
    if papers:
        for paper in papers[:5]:
            lines.append(f"- {paper.get('title', 'unknown')} ({paper.get('year', 'N/A')}) — Authors: {', '.join(paper.get('authors', [])) or 'N/A'}")
    else:
        lines.append("- No papers retrieved.")
    lines.append("")

    if carbon_snapshot:
        lines.append("Carbon intensity snapshot:")
        note = carbon_snapshot.get("note")
        if note:
            lines.append(f"- {note}")
        else:
            lines.append(f"- Provider: {carbon_snapshot.get('provider', 'unknown')}")
            lines.append(f"- Location: {carbon_snapshot.get('location', 'unknown')}")
            if "carbon_intensity" in carbon_snapshot:
                units = carbon_snapshot.get("units") or carbon_snapshot.get("unit") or "gCO2e/kWh"
                lines.append(f"- Carbon intensity: {carbon_snapshot['carbon_intensity']} {units}")
            if "datetime" in carbon_snapshot:
                lines.append(f"- Timestamp: {carbon_snapshot['datetime']}")
    else:
        lines.append("Carbon intensity snapshot unavailable.")

    return "\n".join(lines).strip()


def _render_report(
    *,
    question: str,
    topic: str,
    sdg_matches: List[Dict[str, object]],
    repositories: List[Dict[str, object]],
    papers: List[Dict[str, object]],
    carbon_snapshot: Optional[Dict[str, object]],
    llm_summary: Optional[str],
) -> str:
    lines: List[str] = []
    lines.append(f"# Research Synthesis: {topic}\n")
    lines.append("## Primary Question\n")
    lines.append(question.strip() or "(not provided)")
    lines.append("")

    if llm_summary:
        lines.append("## LLM Synthesis\n")
        lines.append(llm_summary)
        lines.append("")

    lines.append("## SDG Alignment\n")
    if sdg_matches:
        for match in sdg_matches:
            code = match.get("code", "?")
            title = match.get("title", "Unknown goal")
            score = match.get("score", 0)
            lines.append(f"- **SDG {code}** — {title} (score: {score})")
        lines.append("")
    else:
        lines.append("- No SDG matches identified.\n")

    lines.append("## Key Repositories\n")
    if repositories:
        lines.append("| Repository | Stars | Description |")
        lines.append("|------------|-------|-------------|")
        for repo in repositories:
            name = repo.get("full_name", "unknown")
            stars = repo.get("stargazers_count", 0)
            description = (repo.get("description") or "").replace("\n", " ").strip()
            url = repo.get("html_url")
            label = f"[{name}]({url})" if url else name
            lines.append(f"| {label} | {stars} | {description or '—'} |")
        lines.append("")
    else:
        lines.append("No repositories discovered.\n")

    lines.append("## Representative Papers\n")
    if papers:
        for paper in papers:
            title = paper.get("title", "unknown")
            year = paper.get("year") or "?"
            url = paper.get("url")
            authors = ", ".join(paper.get("authors", [])) or "N/A"
            abstract = (paper.get("abstract") or "").strip()
            entry = f"- **{title}** ({year}) — {authors}"
            if url:
                entry += f" — [{url}]({url})"
            lines.append(entry)
            if abstract:
                snippet = abstract[:500]
                suffix = "…" if len(abstract) > 500 else ""
                lines.append(f"  - _Abstract_: {snippet}{suffix}")
        lines.append("")
    else:
        lines.append("No papers retrieved.\n")

    lines.append("## Carbon Intensity\n")
    if carbon_snapshot:
        note = carbon_snapshot.get("note")
        if note:
            lines.append(f"- {note}")
        else:
            lines.append(f"- Provider: {carbon_snapshot.get('provider', 'unknown')}")
            lines.append(f"- Location: {carbon_snapshot.get('location', 'unknown')}")
            if "carbon_intensity" in carbon_snapshot:
                units = carbon_snapshot.get("units") or carbon_snapshot.get("unit") or "gCO2e/kWh"
                lines.append(f"- Carbon intensity: {carbon_snapshot['carbon_intensity']} {units}")
            if "datetime" in carbon_snapshot:
                lines.append(f"- Timestamp: {carbon_snapshot['datetime']}")
        lines.append("")
    else:
        lines.append("- Carbon intensity snapshot unavailable.\n")

    return "\n".join(lines)
